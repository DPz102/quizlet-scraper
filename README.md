# Quizlet Private Flashcard Scraper

Export flashcards tá»« Quizlet, bao gá»“m cáº£ private sets Ä‘Æ°á»£c chia sáº» vá»›i báº¡n.

## Features

- ğŸ” ÄÄƒng nháº­p vÃ  lÆ°u session Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
- ğŸ“š Tá»± Ä‘á»™ng phÃ¡t hiá»‡n táº¥t cáº£ flashcard sets trong thÆ° viá»‡n
- ğŸ”— Há»— trá»£ private sets Ä‘Æ°á»£c share qua classes/folders
- ğŸ“¤ Export ra nhiá»u Ä‘á»‹nh dáº¡ng: JSON, CSV, TSV, Anki
- ğŸ›¡ï¸ Anti-detection vá»›i random delays vÃ  real browser fingerprints
- ğŸ—ï¸ Kiáº¿n trÃºc SOLID, dá»… má»Ÿ rá»™ng

## Installation

```bash
# Clone repo
git clone https://github.com/DPz102/quizet-private-flashcard-scraper.git
cd quizet-private-flashcard-scraper

# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows PowerShell
# source venv/bin/activate   # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
playwright install chromium
```

## Usage

### Basic Usage

```bash
# Run with interactive login
python -m src.main

# With username (will prompt for password)
python -m src.main -u your_email@example.com

# Scrape specific sets
python -m src.main -s "https://quizlet.com/123456789/set-name-flash-cards"

# Export to multiple formats
python -m src.main -f json csv anki

# Run headless (after first login)
python -m src.main --headless
```

### Programmatic Usage

```python
from src.utils.config import ConfigLoader
from src.main import QuizletScraper

config = ConfigLoader("config.yaml")
scraper = QuizletScraper(config)

# Login
scraper.login("your_email", "your_password")

# Discover all sets
sets = scraper.discover_sets()

# Scrape specific sets
scraped = scraper.scrape_sets([s.url for s in sets])

# Export
paths = scraper.export(scraped, formats=["json", "csv"])

scraper.close()
```

## Configuration

Edit `config.yaml`:

```yaml
browser:
  headless: false  # Set true after initial login
  slow_mo: 100     # Delay between actions (ms)

scraper:
  delay_min: 2.0   # Min delay between requests (s)
  delay_max: 5.0   # Max delay between requests (s)

export:
  output_dir: "output"
  formats:
    - json
    - csv
```

## Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/           # Interfaces & exceptions (DIP)
â”‚   â”‚   â”œâ”€â”€ interfaces.py
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â”œâ”€â”€ auth/           # Authentication (SRP)
â”‚   â”‚   â”œâ”€â”€ browser_manager.py
â”‚   â”‚   â””â”€â”€ authenticator.py
â”‚   â”œâ”€â”€ scraper/        # Scraping logic (SRP)
â”‚   â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”‚   â”œâ”€â”€ library_scraper.py
â”‚   â”‚   â””â”€â”€ set_scraper.py
â”‚   â”œâ”€â”€ export/         # Exporters (OCP)
â”‚   â”‚   â”œâ”€â”€ json_exporter.py
â”‚   â”‚   â”œâ”€â”€ csv_exporter.py
â”‚   â”‚   â”œâ”€â”€ anki_exporter.py
â”‚   â”‚   â””â”€â”€ exporter_factory.py
â”‚   â”œâ”€â”€ utils/          # Utilities
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â””â”€â”€ logging_config.py
â”‚   â””â”€â”€ main.py         # Orchestrator
â”œâ”€â”€ auth/               # Session storage (gitignored)
â”œâ”€â”€ output/             # Export output
â”œâ”€â”€ config.yaml
â””â”€â”€ requirements.txt
```

## SOLID Principles Applied

| Principle | Implementation |
|-----------|----------------|
| **S**ingle Responsibility | Each class has one job: `Authenticator` = auth, `SetScraper` = scraping |
| **O**pen/Closed | `BaseExporter` is closed for modification, open for extension |
| **L**iskov Substitution | `TSVExporter` can replace `CSVExporter` anywhere |
| **I**nterface Segregation | Small, focused interfaces: `IAuthenticator`, `IExporter`, `IScraper` |
| **D**ependency Inversion | High-level `QuizletScraper` depends on abstractions, not concretions |

## Legal Notice

âš ï¸ **Important:**
- Chá»‰ scrape data báº¡n cÃ³ quyá»n truy cáº­p há»£p phÃ¡p
- Tool nÃ y dÃ nh cho backup cÃ¡ nhÃ¢n
- TuÃ¢n thá»§ Terms of Service cá»§a Quizlet
- KhÃ´ng redistribute ná»™i dung Ä‘Ã£ scrape

## License

MIT License
